{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "np.set_printoptions(threshold = np.inf)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 100\n",
    "time_step = 0.1\n",
    "min_pitch = 21  # A0\n",
    "max_pitch = 108  # C8\n",
    "n_pitches = max_pitch - min_pitch # 88 possible pitch options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary piano roll sequence : (time, pitch) numpy from a midi file\n",
    "def midi_to_sequence(midi_path):\n",
    "  pm = pretty_midi.PrettyMIDI(midi_path)\n",
    "  # piano_roll : (pitch, time steps) numpy\n",
    "  piano_roll = pm.get_piano_roll(fs=1/time_step)\n",
    "  # Transpose for (time steps, pitch)\n",
    "  piano_roll = piano_roll.T\n",
    "  # Clip to valid pitch range\n",
    "  piano_roll = piano_roll[:, min_pitch: max_pitch+1]\n",
    "  # Convert Velocity information to binary for faster learning and simpler data\n",
    "  binary_roll = (torch.tensor(piano_roll) != 0).float()\n",
    "  return binary_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences : (no of sequences, sequence_length, 88 (possible pitches) ) tensor\n",
    "# and targets : (no of sequences, 88 (possible pitches) ) tensor\n",
    "# from given binary piano roll sequence : (time, 88 (possible pitches) ) numpy\n",
    "def create_sequences(piano_roll):\n",
    "  sequences = []\n",
    "  targets = []\n",
    "\n",
    "  for i in range(0, len(piano_roll) - sequence_length - 1, 1):\n",
    "    seq = piano_roll[i:i + sequence_length]\n",
    "    target = piano_roll[i + sequence_length]\n",
    "    sequences.append(seq)\n",
    "    targets.append(target)\n",
    "      \n",
    "  return torch.stack(sequences), torch.stack(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "targets = []\n",
    "midi_files = list(Path(r\"C:\\Users\\aniru\\Desktop\\projects\\AI Music Generator\\custom\\maestro-v3.0.0\").rglob(\"*.midi\"))\n",
    "count = 0\n",
    "max_count = 100\n",
    "# Combine sequences and targets from max_count number of midi files given in path\n",
    "for midi_file in tqdm(midi_files):\n",
    "  if (count == max_count):\n",
    "    break\n",
    "  try:\n",
    "    piano_roll = midi_to_sequence(str(midi_file))\n",
    "    if piano_roll is not None:\n",
    "      seqs, tgts = create_sequences(piano_roll)\n",
    "      sequences.append(seqs)\n",
    "      targets.append(tgts)\n",
    "      count += 1\n",
    "  except Exception as e:\n",
    "    print(f\"Error processing {midi_file}: {e}\")\n",
    "\n",
    "print(\"Converting training data to tensors\")\n",
    "sequences = torch.cat(sequences, dim=0)\n",
    "targets = torch.cat(targets, dim=0)\n",
    "print(\"Shape of Sequences\")\n",
    "print(sequences.shape)\n",
    "print(\"Shape of Targets\")\n",
    "print(targets.shape)\n",
    "print(\"Converting training data to dataloader\")\n",
    "dataset = TensorDataset(sequences, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=32, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessd data for future use to save time\n",
    "torch.save(sequences, 'anirudh_sequences.pth')\n",
    "torch.save(targets, 'anirudh_targets.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a random midi file after converting its velocity to binary format for reference\n",
    "print(midi_file)\n",
    "piano_roll_tmp = midi_to_sequence(str(midi_file))\n",
    "prev_numpy = piano_roll_tmp.T.numpy()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Original Piano Roll\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Pitch\")\n",
    "plt.imshow(prev_numpy, aspect='auto', origin='lower', cmap='Greens')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicLSTM(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MusicLSTM, self).__init__()\n",
    "    # 256 hidden layers because the more hidden layers, the more complex patterns it can recognize \n",
    "    self.lstm = nn.LSTM(input_size=88, hidden_size=256, num_layers=1, batch_first=True)\n",
    "    self.fc = nn.Linear(256, 88)\n",
    "    # No sigmoid because we use BCE with logits loss\n",
    "      \n",
    "  def forward(self, x, hidden=None):\n",
    "    # x : (batch_size, sequence_length, 88 (possible pitches) ) tensor\n",
    "    out, hidden = self.lstm(x, hidden)\n",
    "    # out : (batch_size, sequence_length, 256) tensor\n",
    "    # Give last layer of out for the final fully connected layer\n",
    "    out = self.fc(out[:, -1, :])\n",
    "    return out, hidden\n",
    "  \n",
    "  def generate(self, seed_sequence, steps=480): #6\n",
    "    self.eval()\n",
    "    current_sequence = seed_sequence.clone().to(\"cuda\")\n",
    "    generated_sequence = torch.zeros((steps, 88), device=\"cuda\")\n",
    "    hidden = None\n",
    "    with torch.no_grad():\n",
    "        for step in tqdm(range(steps)):\n",
    "            # Get model prediction\n",
    "            output, hidden = self(current_sequence, hidden)\n",
    "            # If sigmoid was applied we would keep threshold as >= 0.5 \n",
    "            # but because we use BCE with logits loss to reduce numerical errors\n",
    "            # we keep threshold as >= 0 as sigmoid(0) = 0.5 \n",
    "            output = output >= 0\n",
    "            generated_sequence[step] = output.squeeze()\n",
    "            \n",
    "            # Update the sequence by removing oldest step and adding new one\n",
    "            current_sequence = torch.cat([\n",
    "                current_sequence[:, 1:, :],\n",
    "                output.unsqueeze(1)\n",
    "            ], dim = 1)\n",
    "    return generated_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is generated by chatgpt idk if it works properly\n",
    "# currently validating output by plotting it with matplotlib instead\n",
    "def sequence_to_midi(sequence, output_path):\n",
    "    \"\"\"\n",
    "    Convert generated sequence to MIDI file.\n",
    "    Uses tensors for processing until final MIDI creation.\n",
    "    \n",
    "    Args:\n",
    "        sequence: Tensor of shape (time_steps, 88) with velocities\n",
    "        output_path: Path to save MIDI file\n",
    "        time_step: Time between notes in seconds\n",
    "    \"\"\"\n",
    "    # Create a new MIDI object\n",
    "    pm = pretty_midi.PrettyMIDI(initial_tempo=120)\n",
    "    piano = pretty_midi.Instrument(program=0)  # program 0 is piano\n",
    "    \n",
    "    # Finding note onsets and offsets\n",
    "    # A note starts when velocity goes from 0 to >0\n",
    "    # A note ends when velocity goes from >0 to 0\n",
    "    sequence_padded = torch.cat([\n",
    "        torch.zeros((1, 88)),  # Add zero padding at start\n",
    "        sequence,\n",
    "        torch.zeros((1, 88))   # Add zero padding at end\n",
    "    ])\n",
    "    \n",
    "    # Calculate changes in velocity\n",
    "    velocity_changes = sequence_padded[1:] - sequence_padded[:-1]\n",
    "    \n",
    "    # Find note starts (positive velocity change) and ends (negative velocity change)\n",
    "    note_starts = velocity_changes[:-1] > 0\n",
    "    note_ends = velocity_changes[1:] < 0\n",
    "    \n",
    "    # Convert to numpy for final processing\n",
    "    sequence_np = sequence.numpy()\n",
    "    note_starts_np = note_starts.numpy()\n",
    "    note_ends_np = note_ends.numpy()\n",
    "    \n",
    "    # Create MIDI notes\n",
    "    for pitch in range(88):\n",
    "        # Find all start times for this pitch\n",
    "        start_times = np.where(note_starts_np[:, pitch])[0]\n",
    "        \n",
    "        for start_idx in start_times:\n",
    "            # Find the next end time for this note\n",
    "            end_indices = np.where(note_ends_np[start_idx:, pitch])[0]\n",
    "            if len(end_indices) == 0:\n",
    "                # If no end found, end at the last time step\n",
    "                end_idx = len(sequence) - 1\n",
    "            else:\n",
    "                end_idx = start_idx + end_indices[0]\n",
    "            \n",
    "            # Get the velocity (use max velocity during the note duration)\n",
    "            velocity = int(np.max(sequence_np[start_idx:end_idx + 1, pitch]))\n",
    "            \n",
    "            # Create note (add 21 to pitch to map to MIDI pitch numbers)\n",
    "            note = pretty_midi.Note(\n",
    "                velocity=velocity,\n",
    "                pitch=pitch + 21,  # MIDI starts at A0 (21)\n",
    "                start=start_idx * time_step,\n",
    "                end=(end_idx + 1) * time_step\n",
    "            )\n",
    "            piano.notes.append(note)\n",
    "\n",
    "    pm.instruments.append(piano)\n",
    "    pm.write(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MusicLSTM()\n",
    "criterion = torch.nn.BCEWithLogitsLoss() # did not add sigmoid function in model because we using this\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (sequences, targets) in tqdm(enumerate(dataloader)):\n",
    "        sequences = sequences.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # Predicting without hidden for default hidden = None\n",
    "        logits, hidden = model(sequences)\n",
    "        loss = criterion(logits, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate music\n",
    "# seed_sequence : (sequence_length, 88 (possible pitches) ) tensor in cpu\n",
    "seed_sequence = dataset[10000][0] # A random dataset element's sequence to predict from\n",
    "# seed_sequence : (1, sequence_length, 88 (possible pitches) ) tensor in gpu\n",
    "seed_sequence = seed_sequence.to(device).unsqueeze(0)\n",
    "# generated_sequence : (steps, 88 (possible pitches)) tensor in gpu\n",
    "generated_sequence = model.generate(seed_sequence, steps=600)\n",
    "generated_piano_roll = generated_sequence * 110.0 # Converting binary velocity to a reasonable integer velocity of 110\n",
    "sequence_to_midi(generated_piano_roll.cpu(), \"generated_music.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the generated piano roll for debugging\n",
    "gen_numpy = generated_sequence.T.cpu().numpy()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generated Piano Roll\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Pitch\")\n",
    "plt.imshow(gen_numpy, aspect='auto', origin='lower', cmap='Greens')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For verification purposes\n",
    "print(generated_sequence[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for future testing and optimizer for further training\n",
    "torch.save(model.state_dict(), 'anirudh_model_weights.pth')\n",
    "torch.save(optimizer.state_dict(), 'anirudh_optimizer.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
